{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5babfc62",
   "metadata": {},
   "source": [
    "### Figures\n",
    "This notebook contains the code used to generate the figures in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ce0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv('Data/attributes_lat_lon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353029cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nse(observed, simulated):\n",
    "    denominator = np.sum((observed - np.mean(observed)) ** 2)\n",
    "    numerator = np.sum((simulated - observed) ** 2)\n",
    "    if denominator == 0:\n",
    "        denominator += 1e-10\n",
    "    nse_val = 1 - numerator / denominator\n",
    "    return nse_val\n",
    "\n",
    "def compute_rmse(observed, simulated):\n",
    "    mse = np.square(np.subtract(simulated, observed)).mean()\n",
    "    return math.sqrt(mse)\n",
    "\n",
    "def compute_kge(observed, simulated):\n",
    "    r = pearsonr(observed, simulated)[0]\n",
    "    alpha = np.std(simulated)/np.std(observed)\n",
    "    beta = np.mean(simulated)/np.mean(observed)\n",
    "    value = (r-1)**2 + (alpha-1)**2 + (beta-1)**2\n",
    "    return 1 - np.sqrt(float(value))\n",
    "\n",
    "def compute_bias(sim, obs):\n",
    "    # sse\n",
    "    sse = np.mean((np.mean(sim) - obs)** 2)\n",
    "\n",
    "    # variance\n",
    "    variance = np.var(sim)\n",
    "    \n",
    "    return sse - variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment A basins\n",
    "run_dir = Path(\"Data/runs/a_basins_sl_90_hs_32_0702_182604\")\n",
    "\n",
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    a_results = pickle.load(fp)\n",
    "    \n",
    "for i in a_results:\n",
    "    basin_name = i\n",
    "    qobs = a_results[i]['1D']['xr']['q_cms_obs']\n",
    "    qsim = a_results[i]['1D']['xr']['q_cms_sim']\n",
    "    df = pd.DataFrame({'sim': qsim.to_dataframe().reset_index().q_cms_sim,\n",
    "                       'obs': qobs.to_dataframe().reset_index().q_cms_obs,\n",
    "                       'date': qobs.to_dataframe().reset_index().date}).dropna()\n",
    "    df.index = pd.to_datetime(df.date)\n",
    "    nse = compute_nse(df.obs, df.sim)\n",
    "    rmse = compute_rmse(df.obs, df.sim)\n",
    "    kge = compute_kge(df.obs, df.sim)\n",
    "    r = pearsonr(df.obs, df.sim)[0]\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    ax.plot(df.date, df.obs, label='daily glofas', linestyle='-', color='black', zorder=1)\n",
    "    ax.plot(df.date, df.sim, label='LSTM glofas', color='mediumturquoise', zorder=2, linestyle='-')\n",
    "    ax.legend()\n",
    "    ax.set_ylabel(\"Discharge ($m^3$/s)\")\n",
    "    ax.set_title(f\"{basin_name} - KGE {kge:.2f} - R {r:.2f} - NSE {nse:.2f} - RMSE {rmse:.2f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgroup boxplots\n",
    "a = 'indigo'\n",
    "b = 'steelblue'\n",
    "c = 'darkcyan'\n",
    "d = 'yellowgreen'\n",
    "e = 'gold'\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "plt.boxplot(static_df.loc[static_df.f_groups == 'all', 'f_nse'], positions = [0.0],\n",
    "            patch_artist=True, boxprops=dict(facecolor=a, color=a), medianprops=dict(color='white'))\n",
    "\n",
    "plt.boxplot(static_df.loc[static_df.e_groups == 'A', 'e_nse'], positions = [0.4],\n",
    "            patch_artist=True, boxprops=dict(facecolor=b, color=b), medianprops=dict(color='black'))\n",
    "plt.boxplot(static_df.loc[static_df.e_groups == 'B', 'e_nse'], positions = [0.6],\n",
    "            patch_artist=True, boxprops=dict(facecolor=b, color=b), medianprops=dict(color='black'))\n",
    "plt.boxplot(static_df.loc[static_df.e_groups == 'C', 'e_nse'], positions = [0.8],\n",
    "            patch_artist=True, boxprops=dict(facecolor=b, color=b), medianprops=dict(color='black'))\n",
    "\n",
    "plt.boxplot(static_df.loc[static_df.a_groups == 'low', 'a_nse'], positions = [1.2],\n",
    "            patch_artist=True, boxprops=dict(facecolor=c, color=c), medianprops=dict(color='black'))\n",
    "plt.boxplot(static_df.loc[static_df.a_groups == 'medium', 'a_nse'], positions = [1.4],\n",
    "            patch_artist=True, boxprops=dict(facecolor=c, color=c), medianprops=dict(color='black'))\n",
    "plt.boxplot(static_df.loc[static_df.a_groups == 'high', 'a_nse'], positions = [1.6],\n",
    "            patch_artist=True, boxprops=dict(facecolor=c, color=c), medianprops=dict(color='black'))\n",
    "\n",
    "plt.boxplot(static_df.loc[static_df.b_groups == 'low WB', 'b_nse'], positions = [2.0],\n",
    "            patch_artist=True, boxprops=dict(facecolor=d, color=d), medianprops=dict(color='black'))\n",
    "plt.boxplot(static_df.loc[static_df.b_groups == 'medium WB', 'b_nse'], positions = [2.2],\n",
    "            patch_artist=True, boxprops=dict(facecolor=d, color=d), medianprops=dict(color='black'))\n",
    "plt.boxplot(static_df.loc[static_df.b_groups == 'high WB', 'b_nse'], positions = [2.4],\n",
    "            patch_artist=True, boxprops=dict(facecolor=d, color=d), medianprops=dict(color='black'))\n",
    "\n",
    "plt.boxplot(static_df.loc[static_df.d_groups == 'dam', 'd_nse'], positions = [2.8],\n",
    "            patch_artist=True, boxprops=dict(facecolor=e, color=e), medianprops=dict(color='black'))\n",
    "plt.boxplot(static_df.loc[static_df.d_groups == 'flashy', 'd_nse'], positions = [3.0],\n",
    "            patch_artist=True, boxprops=dict(facecolor=e, color=e), medianprops=dict(color='black'))\n",
    "plt.boxplot(static_df.loc[static_df.d_groups == 'natural', 'd_nse'], positions = [3.2],\n",
    "            patch_artist=True, boxprops=dict(facecolor=e, color=e), medianprops=dict(color='black'))\n",
    "\n",
    "ax.set_xticklabels(['All', 'Random Group 1', 'Random Group 2', 'Random Group 3',\n",
    "                    'Low NSE', 'Med NSE', 'High NSE', 'Low WB',\n",
    "                    'Med WB', 'High WB','Reservoir',\n",
    "                    'Ephemeral', 'Natural'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('NSE')\n",
    "# plt.savefig('Data/images/boxplot_nse.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74cbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# std dev nse scatterplot\n",
    "df_diverse = pd.DataFrame({'subgroup': ['All', 'A', 'B', 'C',\n",
    "                           'low', 'medium', 'high',\n",
    "                           'low WB', 'medium WB', 'high WB',\n",
    "                           'dam', 'flashy', 'natural']})\n",
    "\n",
    "df_diverse['std_norm'] = np.nan\n",
    "df_diverse['nse'] = np.nan\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'All', 'std_norm'] = static_df.std_q.mean()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'A', 'std_norm'] = static_df.loc[static_df.e_groups == 'A', 'std_q'].mean()\n",
    "df_diverse.loc[df_diverse.subgroup == 'B', 'std_norm'] = static_df.loc[static_df.e_groups == 'B', 'std_q'].mean()\n",
    "df_diverse.loc[df_diverse.subgroup == 'C', 'std_norm'] = static_df.loc[static_df.e_groups == 'C', 'std_q'].mean()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'low', 'std_norm'] = static_df.loc[static_df.a_groups == 'low', 'std_q'].mean()\n",
    "df_diverse.loc[df_diverse.subgroup == 'medium', 'std_norm'] = static_df.loc[static_df.a_groups == 'medium', 'std_q'].mean()\n",
    "df_diverse.loc[df_diverse.subgroup == 'high', 'std_norm'] = static_df.loc[static_df.a_groups == 'high', 'std_q'].mean()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'low WB', 'std_norm'] = static_df.loc[static_df.b_groups == 'low WB', 'std_q'].mean()\n",
    "df_diverse.loc[df_diverse.subgroup == 'medium WB', 'std_norm'] = static_df.loc[static_df.b_groups == 'medium WB', 'std_q'].mean()\n",
    "df_diverse.loc[df_diverse.subgroup == 'high WB', 'std_norm'] = static_df.loc[static_df.b_groups == 'high WB', 'std_q'].mean()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'dam', 'std_norm'] = static_df.loc[static_df.d_groups == 'dam', 'std_q'].mean()\n",
    "df_diverse.loc[df_diverse.subgroup == 'flashy', 'std_norm'] = static_df.loc[static_df.d_groups == 'flashy', 'std_q'].mean()\n",
    "df_diverse.loc[df_diverse.subgroup == 'natural', 'std_norm'] = static_df.loc[static_df.d_groups == 'natural', 'std_q'].mean()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'All', 'nse'] = static_df.f_nse.median()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'A', 'nse'] = static_df.loc[static_df.e_groups == 'A', 'e_nse'].median()\n",
    "df_diverse.loc[df_diverse.subgroup == 'B', 'nse'] = static_df.loc[static_df.e_groups == 'B', 'e_nse'].median()\n",
    "df_diverse.loc[df_diverse.subgroup == 'C', 'nse'] = static_df.loc[static_df.e_groups == 'C', 'e_nse'].median()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'low', 'nse'] = static_df.loc[static_df.a_groups == 'low', 'a_nse'].median()\n",
    "df_diverse.loc[df_diverse.subgroup == 'medium', 'nse'] = static_df.loc[static_df.a_groups == 'medium', 'a_nse'].median()\n",
    "df_diverse.loc[df_diverse.subgroup == 'high', 'nse'] = static_df.loc[static_df.a_groups == 'high', 'a_nse'].median()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'low WB', 'nse'] = static_df.loc[static_df.b_groups == 'low WB', 'b_nse'].median()\n",
    "df_diverse.loc[df_diverse.subgroup == 'medium WB', 'nse'] = static_df.loc[static_df.b_groups == 'medium WB', 'b_nse'].median()\n",
    "df_diverse.loc[df_diverse.subgroup == 'high WB', 'nse'] = static_df.loc[static_df.b_groups == 'high WB', 'b_nse'].median()\n",
    "\n",
    "df_diverse.loc[df_diverse.subgroup == 'dam', 'nse'] = static_df.loc[static_df.d_groups == 'dam', 'd_nse'].median()\n",
    "df_diverse.loc[df_diverse.subgroup == 'flashy', 'nse'] = static_df.loc[static_df.d_groups == 'flashy', 'd_nse'].median()\n",
    "df_diverse.loc[df_diverse.subgroup == 'natural', 'nse'] = static_df.loc[static_df.d_groups == 'natural', 'd_nse'].median()\n",
    "\n",
    "df_diverse['exp'] = ['A', 'B', 'B', 'B', 'C', 'C', 'C', 'D', 'D', 'D', 'E', 'E', 'E']\n",
    "\n",
    "plt.scatter(df_diverse.loc[df_diverse.exp == 'A'].std_norm, df_diverse.loc[df_diverse.exp == 'A'].nse, c='indigo', label='Exp A')\n",
    "plt.scatter(df_diverse.loc[df_diverse.exp == 'B'].std_norm, df_diverse.loc[df_diverse.exp == 'B'].nse, c='steelblue', label='Exp B')\n",
    "plt.scatter(df_diverse.loc[df_diverse.exp == 'C'].std_norm, df_diverse.loc[df_diverse.exp == 'C'].nse, c='darkcyan', label='Exp C')\n",
    "plt.scatter(df_diverse.loc[df_diverse.exp == 'D'].std_norm, df_diverse.loc[df_diverse.exp == 'D'].nse, c='yellowgreen', label='Exp D')\n",
    "plt.scatter(df_diverse.loc[df_diverse.exp == 'E'].std_norm, df_diverse.loc[df_diverse.exp == 'E'].nse, c='gold', label='Exp E')\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "\n",
    "for i in df_diverse.subgroup: \n",
    "    plt.annotate(i, (df_diverse.loc[df_diverse.subgroup == i].std_norm, df_diverse.loc[df_diverse.subgroup == i].nse + 0.02)) \n",
    "# plt.legend()\n",
    "# plt.savefig('Data/images/diversity.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment E w/ CA\n",
    "run_dir = Path(\"Data/runs/d_group_dam_sl_365_hs_121_1502_114133\")\n",
    "\n",
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    d_results_a_new = pickle.load(fp)\n",
    "\n",
    "run_dir = Path(\"Data/runs/d_group_flashy_sl_365_hs_121_2002_182807\")\n",
    "\n",
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    d_results_b_new = pickle.load(fp)\n",
    "    \n",
    "run_dir = Path(\"Data/runs/d_group_natural_sl_90_hs_121_2002_215342\")\n",
    "\n",
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    d_results_c_new = pickle.load(fp)\n",
    "\n",
    "# Experiment E\n",
    "run_dir = Path(\"Data/runs/d_group_dam_sl_90_hs_256_3101_194107\")\n",
    "\n",
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    d_results_a = pickle.load(fp)\n",
    "\n",
    "run_dir = Path(\"Data/runs/d_group_flashy_sl_90_hs_256_3101_213002\")\n",
    "\n",
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    d_results_b = pickle.load(fp)\n",
    "    \n",
    "run_dir = Path(\"Data/runs/d_group_natural_sl_90_hs_32_0102_122118\")\n",
    "\n",
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    d_results_c = pickle.load(fp)\n",
    "    \n",
    "# Experiment A\n",
    "run_dir = Path(\"Data/runs/f_basins_sl_90_hs_32_0702_182604\")\n",
    "\n",
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    exp_a_results = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment E v Experiment A: Sample of Reservoir Basin Predictions\n",
    "i = '14763607426'\n",
    "basin_name = ''\n",
    "qobs = d_results_a[i]['1D']['xr']['q_cms_obs']\n",
    "qsim = d_results_a[i]['1D']['xr']['q_cms_sim']\n",
    "qsim_all = exp_a_results[i]['1D']['xr']['q_cms_sim']\n",
    "df = pd.DataFrame({'sim': qsim.to_dataframe().reset_index().q_cms_sim,\n",
    "                   'sim_all': qsim_all.to_dataframe().reset_index().q_cms_sim,\n",
    "                   'obs': qobs.to_dataframe().reset_index().q_cms_obs,\n",
    "                   'date': qobs.to_dataframe().reset_index().date}).dropna()\n",
    "df.index = pd.to_datetime(df.date)\n",
    "nse = compute_nse(df.obs, df.sim)\n",
    "rmse = compute_rmse(df.obs, df.sim)\n",
    "kge = compute_kge(df.obs, df.sim)\n",
    "r = pearsonr(df.obs, df.sim)[0]\n",
    "b_bias = compute_bias(df.sim, df.obs)\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.plot(df.date, df.obs, label='obs', linestyle='-', color='silver', zorder=1, linewidth=4.5)\n",
    "ax.plot(df.date, df.sim, label='Exp E sim', color='gold', zorder=2, linestyle='-', linewidth=2.5)\n",
    "ax.plot(df.date, df.sim_all, label='Exp A sim', color='indigo', zorder=3, linestyle='-', linewidth=2.5)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "# plt.savefig('Data/images/dam_improvement.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSE difference histograms\n",
    "dam_df = static_df.loc[static_df.d_groups == 'dam']\n",
    "flashy_df = static_df.loc[static_df.d_groups == 'flashy']\n",
    "natural_df = static_df.loc[static_df.d_groups == 'natural']\n",
    "\n",
    "plt.hist(dam_df.d_diff_nse, bins=40, color='gray')\n",
    "plt.vlines(0.0, dam_df.d_diff_nse.mean(), 50, color='blue', linestyles='--', linewidth=2)\n",
    "# plt.set_title('Reservoir')\n",
    "# plt.savefig('Data/images/nse_diffa.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(flashy_df.d_diff_nse, bins=40, color='gray')\n",
    "plt.vlines(0.0, flashy_df.d_diff_nse.mean(), 18.5, color='blue', linestyles='--', linewidth=2)\n",
    "# ax2.set_title('Ephemeral')\n",
    "# plt.savefig('Data/images/nse_diffb.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(natural_df.d_diff_nse, bins=40, color='gray')\n",
    "plt.vlines(0.0, natural_df.d_diff_nse.mean(), 8.2, color='blue', linestyles='--', linewidth=2)\n",
    "# ax3.set_title('Natural')\n",
    "# plt.savefig('Data/images/nse_diffc.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4444742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment E w/ CA v Experiment E: Sample of Reservoir Basin Predictions\n",
    "i = '14423617656'\n",
    "basin_name = ''\n",
    "qobs = d_results_a_new[i]['1D']['xr']['q_cms_obs']\n",
    "qsim = d_results_a_new[i]['1D']['xr']['q_cms_sim']\n",
    "qsim_all = d_results_a[i]['1D']['xr']['q_cms_sim']\n",
    "df = pd.DataFrame({'sim': qsim.to_dataframe().reset_index().q_cms_sim,\n",
    "                   'sim_all': qsim_all.to_dataframe().reset_index().q_cms_sim,\n",
    "                   'obs': qobs.to_dataframe().reset_index().q_cms_obs,\n",
    "                   'date': qobs.to_dataframe().reset_index().date}).dropna()\n",
    "df.index = pd.to_datetime(df.date)\n",
    "nse = compute_nse(df.obs, df.sim)\n",
    "rmse = compute_rmse(df.obs, df.sim)\n",
    "kge = compute_kge(df.obs, df.sim)\n",
    "r = pearsonr(df.obs, df.sim)[0]\n",
    "b_bias = compute_bias(df.sim, df.obs)\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.plot(df.date, df.obs, label='obs', linestyle='-', color='silver', zorder=1, linewidth=5.5)\n",
    "ax.plot(df.date, df.sim, label='Exp E w/ CA sim', color='#9A0EEA', zorder=3, alpha=0.8, linestyle='-', linewidth=2.5)\n",
    "ax.plot(df.date, df.sim_all, label='Exp E sim', color='gold', zorder=2, alpha=0.8, linestyle='-', linewidth=2.5)\n",
    "ax.set_title(f\"{basin_name} - KGE {kge:.2f} - R {r:.2f} - NSE {nse:.2f} - RMSE {rmse:.2f}\")\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "# plt.savefig('Data/images/ca_improvement.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap feature importance barplots\n",
    "results = {}\n",
    "for f in features:\n",
    "    results[f] = []\n",
    "    ft = f + '_t'\n",
    "    results[ft] = []\n",
    "    \n",
    "results['NSE'] = []\n",
    "results['group'] = []\n",
    "\n",
    "dam = ['13888737139', '14286853736', '14729335179', '14740465819', '14857052821']\n",
    "\n",
    "for i in dam:\n",
    "    df = pd.read_csv(f'Data/shaps/shapley_ts_{i}.csv')\n",
    "    n_features = 29\n",
    "    shaps = {'f':[], 'maxs': [], 't': [], 'means':[]}\n",
    "    for f in range(0, n_features):\n",
    "        seq = []\n",
    "        for c in df.columns:\n",
    "            a = c.split('_')[0]\n",
    "            b = c.split('_')[1]\n",
    "            if a == str(f):\n",
    "                seq.append(df[c].abs().sum())\n",
    "        shaps['f'].append(f)\n",
    "        shaps['maxs'].append(max(seq))\n",
    "        shaps['t'].append(np.argmax(seq))\n",
    "        shaps['means'].append(np.mean(seq))\n",
    "\n",
    "    shaps_df = pd.DataFrame(shaps)\n",
    "    shaps_df['means_p'] = shaps_df.means/shaps_df.means.sum() * 100\n",
    "\n",
    "    norm = plt.Normalize(shaps_df.t.min(), shaps_df.t.max())\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Blues_r\", norm=norm)\n",
    "    \n",
    "    for v in features:\n",
    "        vt = v + '_t'\n",
    "        v_i = features.index(v)\n",
    "        shap_i = shaps_df.loc[shaps_df.f == v_i, 'means'].item()\n",
    "        t_i = shaps_df.loc[shaps_df.f == v_i, 't'].item()\n",
    "        results[v].append(shap_i)\n",
    "        results[vt].append(t_i)\n",
    "        \n",
    "    nse_i = static_df.loc[static_df['index'] == int(i), 'd_new_nse'].item()\n",
    "    results['NSE'].append(nse_i)\n",
    "    results['group'].append('dam')\n",
    "\n",
    "\n",
    "    pal = sns.color_palette(\"Blues_d\", len(shaps_df))\n",
    "    rank = shaps_df.t.argsort().argsort()\n",
    "    sns.barplot(x=features, y=shaps_df.means_p, palette=np.array(pal[::-1])[rank])\n",
    "    plt.xticks(rotation=90, fontsize=12)\n",
    "    plt.title(i)\n",
    "    plt.ylabel('')\n",
    "#     plt.colorbar(sm)\n",
    "#     plt.savefig(f'Data/images/dam_{i}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "flashy = ['14111286463', '14163313180', '14262493006', '14446761221', '14438236386']\n",
    "\n",
    "for i in flashy:\n",
    "    df = pd.read_csv(f'Data/shaps/shapley_ts_{i}.csv')\n",
    "    n_features = 29\n",
    "    shaps = {'f':[], 'maxs': [], 't': [], 'means':[]}\n",
    "    for f in range(0, n_features):\n",
    "        seq = []\n",
    "        for c in df.columns:\n",
    "            a = c.split('_')[0]\n",
    "            b = c.split('_')[1]\n",
    "            if a == str(f):\n",
    "                seq.append(df[c].abs().sum())\n",
    "        shaps['f'].append(f)\n",
    "        shaps['maxs'].append(max(seq))\n",
    "        shaps['t'].append(np.argmax(seq))\n",
    "        shaps['means'].append(np.mean(seq))\n",
    "\n",
    "    shaps_df = pd.DataFrame(shaps)\n",
    "    shaps_df['means_p'] = shaps_df.means/shaps_df.means.sum() * 100\n",
    "\n",
    "    norm = plt.Normalize(shaps_df.t.min(), shaps_df.t.max())\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Blues_r\", norm=norm)\n",
    "    \n",
    "    \n",
    "    for v in features:\n",
    "        vt = v + '_t'\n",
    "        v_i = features.index(v)\n",
    "        shap_i = shaps_df.loc[shaps_df.f == v_i, 'means'].item()\n",
    "        t_i = shaps_df.loc[shaps_df.f == v_i, 't'].item()\n",
    "        results[v].append(shap_i)\n",
    "        results[vt].append(t_i)\n",
    "        \n",
    "    nse_i = static_df.loc[static_df['index'] == int(i), 'd_new_nse'].item()\n",
    "    results['NSE'].append(nse_i)\n",
    "    results['group'].append('flashy')\n",
    "\n",
    "    pal = sns.color_palette(\"Blues_d\", len(shaps_df))\n",
    "    rank = shaps_df.t.argsort().argsort()\n",
    "    sns.barplot(x=features, y=shaps_df.means_p, palette=np.array(pal[::-1])[rank])\n",
    "    plt.xticks(rotation=90, fontsize=12)\n",
    "    plt.ylabel('')\n",
    "    plt.title(i)\n",
    "#     plt.colorbar(sm)\n",
    "#     plt.savefig(f'Data/images/flashy_{i}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "natural = ['-14895675224', '14373498333', '14427967711', '14945087340', '15173376543']\n",
    "\n",
    "for i in natural:\n",
    "    df = pd.read_csv(f'Data/shaps/shapley_ts_{i}.csv')\n",
    "    n_features = 29\n",
    "    shaps = {'f':[], 'maxs': [], 't': [], 'means':[]}\n",
    "    for f in range(0, n_features):\n",
    "        seq = []\n",
    "        for c in df.columns:\n",
    "            a = c.split('_')[0]\n",
    "            b = c.split('_')[1]\n",
    "            if a == str(f):\n",
    "                seq.append(df[c].abs().sum())\n",
    "        shaps['f'].append(f)\n",
    "        shaps['maxs'].append(max(seq))\n",
    "        shaps['t'].append(np.argmax(seq))\n",
    "        shaps['means'].append(np.mean(seq))\n",
    "\n",
    "    shaps_df = pd.DataFrame(shaps)\n",
    "    shaps_df['means_p'] = shaps_df.means/shaps_df.means.sum() * 100\n",
    "\n",
    "    norm = plt.Normalize(shaps_df.t.min(), shaps_df.t.max())\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Blues_r\", norm=norm)\n",
    "    \n",
    "    for v in features:\n",
    "        vt = v + '_t'\n",
    "        v_i = features.index(v)\n",
    "        shap_i = shaps_df.loc[shaps_df.f == v_i, 'means'].item()\n",
    "        t_i = shaps_df.loc[shaps_df.f == v_i, 't'].item()\n",
    "        results[v].append(shap_i)\n",
    "        results[vt].append(t_i)\n",
    "        \n",
    "    nse_i = static_df.loc[static_df['index'] == int(i), 'd_new_nse'].item()\n",
    "    results['NSE'].append(nse_i)\n",
    "    results['group'].append('natural')\n",
    "\n",
    "    pal = sns.color_palette(\"Blues_d\", len(shaps_df))\n",
    "    rank = shaps_df.t.argsort().argsort()\n",
    "    sns.barplot(x=features, y=shaps_df.means_p, palette=np.array(pal[::-1])[rank])\n",
    "    plt.xticks(rotation=90, fontsize=12)\n",
    "    plt.ylabel('')\n",
    "    plt.title(i)\n",
    "#     plt.colorbar(sm)\n",
    "#     plt.savefig(f'Data/images/natural_{i}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "dam_df = pd.DataFrame(results_df.loc[results_df.group == 'dam'].mean())\n",
    "flashy_df = pd.DataFrame(results_df.loc[results_df.group == 'flashy'].mean())\n",
    "natural_df = pd.DataFrame(results_df.loc[results_df.group == 'natural'].mean())\n",
    "\n",
    "t_cols = []\n",
    "\n",
    "for c in results_df:\n",
    "    if c.split('_')[-1] == 't':\n",
    "        t_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaged shap feature importance barplots\n",
    "pal = sns.color_palette(\"Blues_d\", len(shaps_df))\n",
    "rank = dam_df.T[t_cols].T[0].argsort().argsort()\n",
    "sns.barplot(x=features, y=dam_df.T[features].T[0], palette=np.array(pal[::-1])[rank])\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.ylabel('')\n",
    "# plt.title('Reservoir')\n",
    "#     plt.colorbar(sm)\n",
    "# plt.savefig(f'Data/images/reservoir-all.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "pal = sns.color_palette(\"Blues_d\", len(shaps_df))\n",
    "rank = flashy_df.T[t_cols].T[0].argsort().argsort()\n",
    "sns.barplot(x=features, y=flashy_df.T[features].T[0], palette=np.array(pal[::-1])[rank])\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.ylabel('')\n",
    "# plt.title('Flashy')\n",
    "#     plt.colorbar(sm)\n",
    "# plt.savefig(f'Data/images/flashy-all.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "pal = sns.color_palette(\"Blues_d\", len(shaps_df))\n",
    "rank = natural_df.T[t_cols].T[0].argsort().argsort()\n",
    "sns.barplot(x=features, y=natural_df.T[features].T[0], palette=np.array(pal[::-1])[rank])\n",
    "plt.xticks(rotation=90, fontsize=12)\n",
    "plt.ylabel('')\n",
    "# plt.title('Natural')\n",
    "#     plt.colorbar(sm)\n",
    "# plt.savefig(f'Data/images/natural-all.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# era5 precipitation impact on the model output scatterplot\n",
    "plt.scatter(results_df.loc[results_df.group == 'dam']['ERA5 precip'], results_df.loc[results_df.group == 'dam'].NSE, label='Reservoir', c='#f0f921')\n",
    "plt.scatter(results_df.loc[results_df.group == 'flashy']['ERA5 precip'], results_df.loc[results_df.group == 'flashy'].NSE, label='Ephemeral', c='#cc4778')\n",
    "plt.scatter(results_df.loc[results_df.group == 'natural']['ERA5 precip'], results_df.loc[results_df.group == 'natural'].NSE, label='Natural', c='#0d0887')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "# plt.savefig(f'Data/images/shaps_nse_era5_precip.png', bbox_inches='tight')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9210282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf of NSEs\n",
    "count, bins_count = np.histogram(static_df.f_nse, bins=100)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, linestyle='--', color='black', label=\"Exp A Overall CDF\")\n",
    "\n",
    "count, bins_count = np.histogram(static_df.d_new_nse.dropna(), bins=100)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, color='black', label=\"Exp E w/ CA: Overall CDF\")\n",
    "\n",
    "count, bins_count = np.histogram(static_df.loc[static_df.d_groups == 'dam', 'd_new_nse'], bins=100)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, color='#fde725', label=\"Exp E w/ CA: Reservoir CDF\")\n",
    "\n",
    "count, bins_count = np.histogram(static_df.loc[static_df.d_groups == 'flashy', 'd_new_nse'].dropna(), bins=100)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, color='#35b779', label=\"Exp E w/ CA: Flashy CDF\")\n",
    "\n",
    "count, bins_count = np.histogram(static_df.loc[static_df.d_groups == 'natural', 'd_new_nse'].dropna(), bins=100)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, color='#31688e', label=\"Exp E w/ CA: Natural CDF\")\n",
    "\n",
    "count, bins_count = np.histogram(static_df.loc[static_df.d_groups == 'dam', 'f_nse'], bins=100)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, linestyle='--', color='#fde725', label=\"Exp A: Reservoir CDF\")\n",
    "\n",
    "count, bins_count = np.histogram(static_df.loc[static_df.d_groups == 'flashy', 'f_nse'].dropna(), bins=100)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, linestyle='--', color='#35b779', label=\"Exp A: Flashy CDF\")\n",
    "\n",
    "count, bins_count = np.histogram(static_df.loc[static_df.d_groups == 'natural', 'f_nse'].dropna(), bins=100)\n",
    "pdf = count / sum(count)\n",
    "cdf = np.cumsum(pdf)\n",
    "plt.plot(bins_count[1:], cdf, linestyle='--', color='#31688e', label=\"Exp A: Natural CDF\")\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "# plt.legend()\n",
    "# plt.savefig('Data/images/nses_cdf.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-vote] *",
   "language": "python",
   "name": "conda-env-miniconda3-vote-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
